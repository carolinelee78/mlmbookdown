# What is MLM used for? 

- When we think of repeated measures, we usually think of change over time as our primary outcome. However, MLM for longitudinal data is used not only to investigate change over Time (i.e., the growth curve of outcome over time) _but also_ to examine the covariation of a variable with an outcome over time (as in a diary study in which you are interested in how 2 variables relate to each other within-individuals over time). These relations over time can be expanded to investigate causal inference as we will see later.
- In the case of growth curve models (change over time), time is a predictor of outcome and it can be modeled as curvilinear as well as linear. Modeling the “correct” growth curve will be important.
- In the “covariation” models, Time may or may not be included in the model depending on whether you think that there may some systematic change in outcome over time. In these models, your predictor is the repeated measurements of your IV (e.g., mood) predicting repeated measurements of your DV (e.g., grades in school).

## Levels of analyses in MLM 

In MLM, your data is organized at multiple levels, and we need to distinguish _between-person relationships_ from _within-person relationships_. The phrase **between-person** simply refers to the existence of **interindividual variation** (i.e., differences between people). The term **between-person relationships** is used to capture how individual differences on one outcome are related to individual differences on another outcome. People can also differ from each other in stable attributes, such as ethnicity or biological sex. People can also differ from each other in attributes like intelligence, personality, or SES that could potentially change over time. But if those attributes are assessed at only a single point in time, then those values obtained at that particular occasion are assumed to be stable and reflective of the person as a whole - in other words, the attributes are considered **time-invariant**. Thus, the phrase _between-person_ refers to relationships among _interindividual differences_ in variables that are _time-invariant_. Furthermore, in the longitudinal models to be presented, the between-person level of analysis is usually labeled as **level 2**, or the **macro** level of analysis. 

### Level 1

The level-1 equation is the equation for the **“within-subject” change over time** (or the within-subject relation between 2 variables over time). This can be the relation between time and outcome (as in the graph below) or the relation between a predictor and outcome over time. In the case of linear time predicting outcome, the regression equation for each person is: 
$$ Y_j = b_0 + b_1 * T_j + \epsilon_j $$
where $Y_j$ is the outcome of assessment $j$, $T_j$ is TIme at assessment $j$ (often coded as 0-$k$, where $k$ is the number of weeks since baseline), $epsilon_j$ is the error in predicting the outcome at assessment $j$, $b_0$ is the intercept, and $b_11$ is the slope of outcome over time. 

In MLM, the parameters in this model (e.g., the intercept and slope) are calculated for each individual in the study and can be different for each individual. If $i$ represents the different individuals in your study, equation 1 can be written for **_all_** the individuals as: 
$$ Y_{ij} = b_{0i} + b_{1i}*T_{ij} + \epsilon_{ij} $$
So, each individual has a different intercept and a different slope. Each person has their _own_ growth curve that best fits their own data. 
```{r, echo = FALSE, out.width="50%", fig.align = 'center'}
knitr::include_graphics("https://raw.githubusercontent.com/carolinelee78/mlmbookdown/main/_figures/IMG1.png")
```

The value of the intercept depends on how time is coded since the intercept is the expected value of the outcome when all other variables in the equation are 0. Thus, if time is coded 0, 1, 2, 3, the intercept is the expected value of $Y$ at “baseline” (the first assessment). If time is coded 1,2,3,4, the intercept is still the expected value when time=0, but in this case, it would be meaningless.

The error in the level-1 model is the error in predicting each data point for each person. Each person has an error at each time point, so these errors can be considered variables $e_1 ... e_k$, if there are $k$ assessments. The variance of the error at each time point is referred to as $\sigma_{j}^2$. The error variance is assumed to be equal at each time point in most simple MLM analyses, but the error covariance matrix can be specified in a more complex manner. The $\epsilon_{ij}$ are assumed to be normally distributed.

```{r, echo = FALSE, out.width="50%", fig.align = 'center'}
knitr::include_graphics("https://raw.githubusercontent.com/carolinelee78/mlmbookdown/main/_figures/IMG2.png")
```
This same kind of model can be used to calculate the relation between 2 variables over time (e.g., the relation between mood and lung function each day in a diary study). Time is often not included in these models when one does not have a treatment or there is no reason to believe that the variables will change systematically over time (like in a short term diary study). However, time can be included as an additional predictor of outcome if the study covers some developmental phases of life so that the outcome is expected to change. The model examining whether mood affects lung function over a 30 day diary study would be:

$$ {FEV}_{ij} = b_{0i} + b_{1i}*{Mood}_{ij} + \epsilon_{ij}$$
where ${FEV}_{ij}$ is lung function for individual $i$ at assessment $j$, $Mood_{ij}$ is the mood for individual $i$ at assessment $j$, $b_{0i}$ is the intercept for individual $i$, and $b_{1i}$ is the relation between $Mood$ and $FEV$ for individual $i$ over time. 

These basic equations all model the relation between predictors and outcome within-subjects over time. These equations that model the repeated measures within-subjects over time is called the level-1 model.

```{r, echo = FALSE, out.width="50%", fig.align = 'center'}
knitr::include_graphics("https://raw.githubusercontent.com/carolinelee78/mlmbookdown/main/_figures/IMG3.png")
```

### Level 2

There is a level-2 equation (level-2 being the level of the individual) for each parameter in the level-1 equation (e.g., the intercept ($b_0$) and the slope ($b_1$) and any other predictors). So we have a slope and intercept for each level-2 person (each individual). The level-2 equations each have an error term, which represents the difference between each person’s slope (or intercept) and the “average” slope (or intercept). These error terms are called the *random effects*! Random effects are assumed to be normally distributed, and are assumed to be uncorrelated with the level 1 error variance ($\epsilon_{ij}$). But they can be correlated with each other. These level 2 equations have an $N$ equal to the number of subjects. The level-1 equation has an N equal to the number of total data points (number of subjects times number of assessments per subject). Examples of simple level 2 equations are:

$$b_{0i} = \gamma_{00} + \mu_{0i}$$ 
$$b_{1i} = \gamma_{10} + \mu_{1i}$$

In this model, $\gamma_{00}$ is the average intercept for the sample (across individuals) and $\gamma_{10}$ is the average slope across individuals. These are called the *fixed effects*, and their significance can be tested, thereby telling you if the intercept is significant, and if there is a significant relation between Time and outcome over the whole sample.

The variance of the error terms ($\mu_{0i}$ and $\mu_{1i}$) can be tested for significance. If the variance for the slopes is significant, that means that there is significant variability between individuals in their slopes of change over time. Notice, this way of analyzing the data breaks the error variance down into 2 components: between subjects variations and within-subjects variation.

A combined model can be created by substituting the level-2 equations into the level-1 model. In this case, the combined model (also called composite model) is:

$$ Y_{ij} = b_{0i} + b_{1i}*T_{ij} + \epsilon_{ij} $$
$$=(\gamma_{00}+\mu_{0i})+(\gamma_{10}+\mu_{1i})*T_{ij}+\epsilon_{ij} $$
$$ =\gamma_{00} + \gamma_{10}*T_{ij}+\mu_{0i}+\mu_{1i}*T_{ij} + \epsilon_{ij} $$
Data in the data file must be “restructured” (i.e., changed into a stacked/long format) so that there is one line per asmt in the data file. To fit a typical regression line to data (not using MLM), you have each data point on a different line. Thus, for MLM, each data point for each person is on a separate line, and each individual is stacked below each other. Go to the “Data” dropdown menu, select “restructure”, and proceed.

### Summary

The purpose of this section was to introduce some of the recurring themes in longitudinal analysis. In terms of levels of analysis, longitudinal data provide information, about _between-person_ relationships (i.e., level-2, time-invariant relationships for attributes measured only once, or for their average values over time), as well as about _within-person_ relationships (i.e., level-1, time-varying relationships for attributes measured repeatedly that vary over time). Longitudinal data can be organized along a continuum ranging from _within-person fluctuation_, which is often the goal of short-term studies (e.g., daily diary or ecological momentary assessment studies), to _within-person change_, which is often the goal of longer-term studies (e.g., data collected over multiple years in order to observe systematic change). In reality, however, these distinctions may not always be so obvious and will need to be examined empirically. Then, we turned to the statistical aspects of longitudinal data, beginning by describing the two-sided lens through which we can view any statistical model. On one side is its _model for the means_ (i.e., fixed effects), which is how the predictors combine to create an expected outcome for each observation. The longitudinal models to be presented differ froom general linear models primarily in their model for the variance, for which we will now make choices, rather than assumptions. Longitudinal models scan generally be estimated as multilevel models (used predominantly thorughout the text, and which require a stacked or long data format) or as structural equation models (used for assessing mediation and changes in latent variables, and which generally require a multivariate or wide data format).

Basically, in longitudinal models: 
  - Level 1: describes the within-person relationships 
    * Predictors explain occasion-to-occasion variation for individuals with respect to their own level 
  - Level 2: describes the between-person relationships
    * Average levels of the predictors explain average levels of the outcome for each individual 
    
## Homework 1 - 08/29

Restructure the OCD mediation file, which is structured as a wide, flat file, with one line per subject. There are 2 DVs: `YBOC` (a measure of OCD symptoms) and `BDI` (Beck Depression Inventory). There are 5 assessments of each, at pre, week 4, week 16, week 26, and week 52. Restructure the file so that there is one line per assessment (5 lines per subject).
 
Then, make an attempt to run a simple MLM. DV should be `YBOC`. The covariates should be `index1` and `condition` (just like in class). The only random effect should be the intercept.
 
Chapter 2 in Heck includes instructions on restructuring, and Chapter 3 has instructions on simple MLM. Since we are using scaled identity as our covariance type, you can follow the example in Heck and ignore the "repeated measures" box and the covariance type. I used these inputs in my example because we will be using it most of the time in the future. But scaled identity is the default value for the covariance, so you don’t need to put it in.

**SPSS**
```
* STEP 1. Restructure dataset.

/VARSTOCASES 
  /MAKE YBOC FROM YBOCpre YBOC4 YBOC16 YBOC26 YBOC52
  /MAKE BDI FROM BDIpre BDI4 BDI16 BDI26 BDI52
  /INDEX=index1(5)
  /KEEP=Subject# Age condition HAMTOT Male0
  /NULL=KEEP
```

```
* STEP 2. Run Simple MLM with DV as YBOC and covariates as index1 and condition, and with random effect for the intercept only. 

MIXED YBOC WITH Index1 condition   
  /CRITERIA=DFMETHOD(SATTERTHWAITE) CIN(95) MXITER(100) MXSTEP(10) SCORING(1)    
  SINGULAR(0.000000000001) HCONVERGE(0.00000001, RELATIVE) LCONVERGE(0, ABSOLUTE) PCONVERGE(0,     
  ABSOLUTE)   
  /FIXED=Index1 condition Index1*condition | SSTYPE(3)  
  /METHOD=REML   /PRINT=SOLUTION TESTCOV  
  /RANDOM=INTERCEPT | SUBJECT(Subject#) COVTYPE(VC)   
  /REPEATED=Index1 | SUBJECT(Subject#) COVTYPE(ID). 
```

```{r, echo = FALSE}
knitr::include_graphics("https://raw.githubusercontent.com/carolinelee78/mlmbookdown/main/_figures/IMG10.png")
```

**Interpretation of** _**Index1**_ $\times$ _**Condition**_ **Interaction**

There’s a significant difference in the effect of time (Index1) on YBOCS. condition moderates the effect of time (Index1) on YBOCS.

**Interpretation of** _**Index1**_ **Main Effect**

Because there is an interaction between time (Index1) and condition, -.320 is the change over time (Index1) in YBOCS scores in people with condition coded 0. This is the decrease in YBOC over time for people in behavioral therapy. .32 decrease for each unit change, where units are assessments.

**Interpretation of** _**condition**_ **Main Effect**

The effect of condition on YBOCS when index1=0, this is meaningless because of how it’s coded. Need to recode index to start at 0 (Index1-1 because 1-5) and then re-run SPSS model with new index variable. The only thing that will change is the condition estimate. 

**Interpretation of Covariance Parameters**

Repeated measures is the variance of ($\epsilon_{ij}$ for level 1 – error at level 1. How far off each actual data point is from the line). We are more interested in the intercept variable, which is the random effect (the composite model ($\mu$s are called random effects in a level 2 equation, the variability between people of whatever that parameter is). Variability in each line for each person, basically the start point. If intercept is at the end, it's the variability of the end scores. If it’s at the beginning, it’s the variability of the baseline. 

**R**

```{r}
library(haven)
library(lme4)

DF1 <- read_sav("Restructured_OCDMediationYBOCSBDI1inS.sav")
model1 <- lmer(YBOC ~ Index1 + condition + Index1:condition + (1 | Index1), data = DF1, na.action = na.exclude)
summary(model1)
```





